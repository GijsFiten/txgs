{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "596c7cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import yaml\n",
    "import numpy as np\n",
    "import imageio.v2 as imageio\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['text.usetex'] = False\n",
    "\n",
    "from utils.dataset_helper import create_dataloaders, create_train_val_dataloaders\n",
    "from vae_model import GaussianVAE, vae_loss_sinkhorn\n",
    "from utils.training_utils import get_warmup_cosine_scheduler\n",
    "from utils.vae_utils import sample_from_latent, save_target_visualization, visualize_reconstruction\n",
    "from utils.image_utils import render, render_and_save\n",
    "from utils.diffusion_data_helper import denormalize_data\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "config_path = \"config/vae_training.yaml\"\n",
    "checkpoint_path = \"best_gaussian_vae.pth\"\n",
    "\n",
    "with open(config_path, \"r\") as f:\n",
    "        cfg = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ba1eaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22084 files in ./data/FFHQ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianVAE(\n",
       "  (sa1): PointNetSetAbstractionMsg(\n",
       "    (conv_blocks): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (bn_blocks): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0-1): 2 x BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0-1): 2 x BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (sa2): PointNetSetAbstractionMsg(\n",
       "    (conv_blocks): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): Conv2d(322, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1-2): 2 x ModuleList(\n",
       "        (0): Conv2d(322, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (bn_blocks): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0-1): 2 x BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1-2): 2 x ModuleList(\n",
       "        (0-1): 2 x BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (sa3): PointNetSetAbstraction(\n",
       "    (mlp_convs): ModuleList(\n",
       "      (0): Conv2d(642, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (mlp_bns): ModuleList(\n",
       "      (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (fc_mu): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (fc_logvar): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (decoder): GaussianTransformerDecoder(\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head_xy): Linear(in_features=256, out_features=2, bias=True)\n",
       "    (head_scale): Linear(in_features=256, out_features=2, bias=True)\n",
       "    (head_rot): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (head_color): Linear(in_features=256, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GaussianVAE(\n",
    "            num_gaussians=cfg[\"model\"][\"num_gaussians\"],\n",
    "            input_dim=cfg[\"model\"][\"input_dim\"],\n",
    "            latent_dim=cfg[\"model\"][\"model_dim\"],\n",
    "            decoder_layers=cfg[\"model\"].get(\"decoder_transformer_layers\", 6),\n",
    "            decoder_heads=cfg[\"model\"].get(\"decoder_transformer_heads\", 8)\n",
    "        ).to(device)\n",
    "\n",
    "data_loader, _ = create_dataloaders(\n",
    "    \"./data/FFHQ\",\n",
    "    batch_size=1, \n",
    "    shuffle=True, \n",
    "    augment=False,\n",
    "    is_distributed=False\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd1c08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 150 frames for 5s video at 30 fps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mu1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m alpha = i / (num_frames - \u001b[32m1\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Interpolate in latent space\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m latent_interp = (\u001b[32m1\u001b[39m - alpha) * \u001b[43mmu1\u001b[49m + alpha * mu2\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Decode and render\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[31mNameError\u001b[39m: name 'mu1' is not defined"
     ]
    }
   ],
   "source": [
    "# Video parameters\n",
    "fps = 30\n",
    "duration = 5  # seconds\n",
    "num_frames = fps * duration\n",
    "\n",
    "# Output path\n",
    "output_dir = \"output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "video_path = os.path.join(output_dir, \"latent_interpolation.mp4\")\n",
    "\n",
    "print(f\"Generating {num_frames} frames for {duration}s video at {fps} fps...\")\n",
    "\n",
    "# Get two random samples from the dataset\n",
    "data_iter = iter(data_loader)\n",
    "data1 = next(data_iter)[0].to(device)\n",
    "data2 = next(data_iter)[0].to(device)\n",
    "\n",
    "# Encode to get latent means\n",
    "with torch.no_grad():\n",
    "    mu1, logvar1 = model.encode(data1)\n",
    "    mu2, logvar2 = model.encode(data2)\n",
    "\n",
    "# Create video writer (requires imageio-ffmpeg backend)\n",
    "with imageio.get_writer(video_path, fps=fps, format=\"FFMPEG\", codec=\"libx264\", quality=8) as writer:\n",
    "    for i in tqdm(range(num_frames)):\n",
    "        # Calculate alpha (0 to 1)\n",
    "        alpha = i / (num_frames - 1)\n",
    "        \n",
    "        # Interpolate in latent space\n",
    "        latent_interp = (1 - alpha) * mu1 + alpha * mu2\n",
    "        \n",
    "        # Decode and render\n",
    "        with torch.no_grad():\n",
    "            decoded = model.decode(latent_interp)\n",
    "        \n",
    "        xy, scale, rot, feat = denormalize_data(decoded[:, :, 0:2], decoded[:, :, 2:4], \n",
    "                                                decoded[:, :, 4:5], decoded[:, :, 5:8])\n",
    "        \n",
    "        xy = xy.squeeze(0).contiguous().float()\n",
    "        scale = scale.squeeze(0).contiguous().float()\n",
    "        rot = rot.squeeze(0).contiguous().float()\n",
    "        feat = feat.squeeze(0).contiguous().float()\n",
    "        \n",
    "        img_size = (int(480), int(640))\n",
    "        image = render(xy, scale, rot, feat, img_size=img_size)\n",
    "        image_np = image.cpu().detach().permute(1, 2, 0).numpy()\n",
    "        \n",
    "        # Convert to uint8 (0-255 range)\n",
    "        image_uint8 = (np.clip(image_np, 0, 1) * 255).astype(np.uint8)\n",
    "        writer.append_data(image_uint8)\n",
    "\n",
    "print(f\"Video saved to {video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b99ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
